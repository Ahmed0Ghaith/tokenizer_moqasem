# Tokenizer Moqasem 


**Intelligent tokenization plugin with advanced Arabic support, fuzzy matching, and AI-powered text analysis.**

> âš¡ **AI Disclaimer:** This plugin was created with 95% AI assistance, showcasing the power and potential of modern AI-powered development tools.

## âœ¨ Features

### ğŸ”¤ Advanced Tokenization
- **Multiple Strategies**: Word, sentence, character, whitespace, n-gram, and custom regex patterns
- **Multi-Language Support**: Arabic, English, and mixed text
- **Smart Processing**: Configurable lowercase, punctuation removal, and stop words filtering

### ğŸ¯ Fuzzy Matching
- **Levenshtein Distance**: Calculate edit distance between strings
- **Word Similarity**: Percentage-based similarity scoring
- **Typo Tolerance**: Find matches even with spelling errors
- **Configurable Threshold**: Adjust matching sensitivity

### ğŸ‡¸ğŸ‡¦ Arabic Language Support
- **Text Normalization**: Automatic diacritics removal (Tashkeel)
- **Alef Variations**: Normalize Ø£ØŒ Ø¥ØŒ Ø¢ â†’ Ø§
- **Taa Marbuta**: Handle Ø© â†’ Ù‡ conversion
- **Number Conversion**: Arabic numerals (Ù -Ù©) to English (0-9)
- **Phonetic Matching**: Sound-based similarity for Arabic characters
- **Root Extraction**: Basic Arabic stemming

### ğŸ“Š Text Analysis
- **Similarity Metrics**: Jaccard and Cosine similarity
- **Token Frequency**: Word count and frequency analysis
- **Language Detection**: Automatic language identification
- **Sentiment Analysis**: Basic positive/negative sentiment scoring
- **Batch Processing**: Efficient processing of multiple texts

### âš¡ Performance
- **Caching System**: Optimized repeated operations
- **Efficient Algorithms**: Optimized regex patterns
- **Lazy Loading**: Memory-efficient for large datasets

## ğŸ“¦ Installation

Add this to your package's `pubspec.yaml` file:

```yaml
dependencies:
  tokenizer_moqasem: ^1.0.0
```

Then run:

```bash
flutter pub get
```

## ğŸš€ Usage

### Basic Tokenization

```dart
import 'package:tokenizer_moqasem/tokenizer_moqasem.dart';

// Create tokenizer with default config
final tokenizer = Tokenizer();

// Tokenize text
final text = 'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©';
final tokens = tokenizer.tokenize(text);
print(tokens); // [Ù…Ø±Ø­Ø¨Ø§, Ø¨Ùƒ, ÙÙŠ, Ø¹Ø§Ù„Ù…, Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©]

// Get token count
print(tokenizer.countTokens(text)); // 5

// Get unique tokens
print(tokenizer.uniqueTokens(text)); // {Ù…Ø±Ø­Ø¨Ø§, Ø¨Ùƒ, ÙÙŠ, Ø¹Ø§Ù„Ù…, Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©}
```

### Custom Configuration

```dart
final config = TokenizerConfig(
  type: TokenizationType.word,
  toLowerCase: true,
  removePunctuation: true,
  removeStopWords: true,
  normalizeArabic: true,
  useFuzzyMatching: true,
  fuzzyThreshold: 0.7,
);

final tokenizer = Tokenizer(config: config);
```

### Fuzzy Matching (Typo Tolerance)

```dart
final tokenizer = Tokenizer(
  config: TokenizerConfig(
    useFuzzyMatching: true,
    fuzzyThreshold: 0.7,
  ),
);

// Compare sentences with typos
final query = 'Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¯Ù‡Ø¨ Ø§Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø±Ø³Ù‡'; // Contains typos
final sentences = [
  'Ø§Ù„Ø·Ø§Ù„Ø¨ Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø±Ø³Ø©',
  'Ø§Ù„ØªÙ„Ù…ÙŠØ° Ø°Ù‡Ø¨ Ù„Ù„Ù…Ø¯Ø±Ø³Ø©',
  'Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¬Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø¯Ø±Ø³Ø©',
];

final results = tokenizer.compareSentences(query, sentences);
for (final result in results) {
  print('${result.rank}. ${result.percentage.toStringAsFixed(2)}% - ${result.sentence}');
}
```

### Arabic Text Processing

```dart
// Normalize Arabic text
final text = 'Ø£ÙÙ„Ø³ÙÙ‘Ù„Ø§Ù…Ù Ø¹ÙÙ„ÙÙŠÙ’ÙƒÙÙ…Ù’';
final normalized = tokenizer.normalizeArabicText(text);
print(normalized); // Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…

// Convert Arabic numbers
final arabicNum = 'Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©';
final english = tokenizer.arabicToEnglishNumbers(arabicNum);
print(english); // 0123456789

// Extract numbers
final mixedText = 'Ù„Ø¯ÙŠ Ù¥ ØªÙØ§Ø­Ø§Øª Ùˆ 3 Ø¨Ø±ØªÙ‚Ø§Ù„Ø§Øª';
final numbers = tokenizer.extractNumbers(mixedText);
print(numbers); // {arabic: [Ù¥], english: [3]}
```

### Similarity Calculation

```dart
// Word similarity
final sim = tokenizer.wordSimilarityPercentage('Ù‚Ø§Ù„', 'Ø¯Ø§Ù„');
print('${(sim * 100).toStringAsFixed(1)}%'); // 75.0%

// Sentence similarity (Cosine)
final sim1 = tokenizer.fuzzyCosineSimilarity(
  'I love programming',
  'I enjoy coding'
);

// Sentence similarity (Jaccard)
final sim2 = tokenizer.fuzzyJaccardSimilarity(
  'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ',
  'Ù…Ø±Ø­Ø¨Ø§ Ø¨ÙƒÙ…'
);
```

### Language Detection

```dart
final lang1 = tokenizer.detectLanguage('Hello World');
print(lang1); // Language.english

final lang2 = tokenizer.detectLanguage('Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ');
print(lang2); // Language.arabic

final lang3 = tokenizer.detectLanguage('Hello Ù…Ø±Ø­Ø¨Ø§Ù‹');
print(lang3); // Language.mixed
```

### N-Gram Tokenization

```dart
final tokenizer = Tokenizer(
  config: TokenizerConfig(
    type: TokenizationType.ngram,
    ngramSize: 2,
  ),
);

final text = 'natural language processing';
final ngrams = tokenizer.tokenize(text);
print(ngrams); // [natural language, language processing]
```

### Sentiment Analysis

```dart
final sentiment = tokenizer.analyzeSentiment('Ù‡Ø°Ø§ Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ø§Ù‹!');
print(sentiment.score); // Positive score
print(sentiment.label); // 'positive' or 'negative' or 'neutral'
```

### Batch Processing

```dart
final texts = [
  'Ø§Ù„Ù†Øµ Ø§Ù„Ø£ÙˆÙ„',
  'Ø§Ù„Ù†Øµ Ø§Ù„Ø«Ø§Ù†ÙŠ',
  'Ø§Ù„Ù†Øµ Ø§Ù„Ø«Ø§Ù„Ø«',
];

final allTokens = texts.map((t) => tokenizer.tokenize(t)).toList();
final similarities = tokenizer.compareAllPairs(texts);
```

## ğŸ¨ Advanced Examples

### Finding Similar Sentences with Word Matches

```dart
final tokenizer = Tokenizer(
  config: TokenizerConfig(useFuzzyMatching: true),
);

final query = 'ÙˆÙ‚Ø§Ù„ Ù„Ù‡ Ø§Ø°Ù‡Ø¨';
final sentences = [
  'Ù‚Ø§Ù„ Ù„Ù‡ Ø§Ø°Ù‡Ø¨ Ù„Ù„Ù…Ø¯Ø±Ø³Ø©',
  'Ùˆ Ø¯Ø§Ù„ Ù„Ù‡ Ø§Ø°Ù‡Ø¨',  // Typo
  'ÙˆÙ‚Ø§Ù„ Ù„Ù‡Ù… Ø§Ø°Ù‡Ø¨ÙˆØ§',
];

final results = tokenizer.compareSentences(
  query,
  sentences,
  showWordMatches: true,
);

for (final result in results) {
  print(result); // Shows word-by-word matches
}
```

### Custom Stop Words

```dart
final customStopWords = {'ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'the', 'a', 'an'};

final tokenizer = Tokenizer(
  config: TokenizerConfig(
    removeStopWords: true,
    stopWords: customStopWords,
  ),
);
```

### Custom Regex Pattern

```dart
final tokenizer = Tokenizer(
  config: TokenizerConfig(
    type: TokenizationType.custom,
    customPattern: RegExp(r'@[\w\u0600-\u06FF]+'), // Match mentions
  ),
);

final text = 'Hello @user Ù…Ø±Ø­Ø¨Ø§Ù‹ @Ù…Ø³ØªØ®Ø¯Ù…';
final mentions = tokenizer.tokenize(text);
print(mentions); // [@user, @Ù…Ø³ØªØ®Ø¯Ù…]
```

## ğŸ“Š Performance Tips

1. **Use Caching**: Tokenizer automatically caches results for repeated operations
2. **Batch Processing**: Process multiple texts together for better performance
3. **Adjust Threshold**: Lower fuzzy threshold (0.6-0.7) for faster matching
4. **Disable Features**: Turn off unused features like stop words removal

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with 95% AI assistance using Claude (Anthropic)
- Special thanks to the Flutter and Dart communities
- Arabic language processing inspired by various NLP research

## ğŸ“§ Contact

- GitHub: [@Ahmed Ghaith](https://github.com/Ahmed0Ghaith)
- Email: devghaith@outlook.com

## ğŸŒŸ Support

If you find this package helpful, please give it a â­ï¸ on [GitHub](https://github.com/Ahmed0Ghaith/tokenizer_moqasem)!

---

**Made with â¤ï¸ and ğŸ¤– AI** | Â© 2025 Ahmed Ghaith